{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003e9fff-734e-4a58-b495-9d3036adde4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from random import gauss\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, concatenate\n",
    "from tensorflow.keras.layers import concatenate, Dense, Softmax, Multiply, Add\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.makedirs('trained_model', exist_ok=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251ec120-65c2-4413-bfe0-72e38a565528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1_train shape: (4950000, 4)\n",
      "x2_train shape: (4950000, 21, 12)\n",
      "y_train shape: (4950000, 20)\n",
      "x1_val shape: (50000, 4)\n",
      "x2_val shape: (50000, 21, 12)\n",
      "y_val shape: (50000, 20)\n",
      "x1_test shape: (100000, 4)\n",
      "x2_test shape: (100000, 7, 12)\n",
      "y_test shape: (100000, 20)\n"
     ]
    }
   ],
   "source": [
    "def load_datasets(path='simulation_data/', string='M1_M20_train_val_test_set'):\n",
    "    if not path.endswith('/'):\n",
    "        path += '/'\n",
    "    filenames = ['x1_train', 'x2_train', 'y_train', 'x1_val', 'x2_val', 'y_val', 'x1_test', 'x2_test', 'y_test']\n",
    "    data = []\n",
    "    for file_name in filenames:\n",
    "        file_path = path + file_name + '_' + string + '.pkl'\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data.append(pickle.load(f))\n",
    "    return data\n",
    "\n",
    "x1_train, x2_train, y_train, x1_val, x2_val, y_val, x1_test, x2_test, y_test = \\\n",
    "    load_datasets(path='simulation_data/', string='M1_M20_train_val_test_set')\n",
    "\n",
    "print(\"x1_train shape:\", x1_train.shape)\n",
    "print(\"x2_train shape:\", x2_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x1_val shape:\", x1_val.shape)\n",
    "print(\"x2_val shape:\", x2_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"x1_test shape:\", x1_test.shape)\n",
    "print(\"x2_test shape:\", x2_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b15082-aa84-4c16-be65-f89119c8f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (4950000, 20)\n",
      "Format: one-hot encoding\n",
      "\n",
      "Unique mechanism labels in y_train: ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07', 'M08', 'M09', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20']\n",
      "Sample 1 (index 2647414): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M11\n",
      "Sample 2 (index 1027977): One-hot: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M05\n",
      "Sample 3 (index 3993827): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], Mechanism Label: M17\n",
      "Sample 4 (index 2955156): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M12\n",
      "Sample 5 (index 319154): One-hot: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M02\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "y_val shape: (50000, 20)\n",
      "Format: one-hot encoding\n",
      "\n",
      "Unique mechanism labels in y_val: ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07', 'M08', 'M09', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20']\n",
      "Sample 1 (index 33553): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], Mechanism Label: M14\n",
      "Sample 2 (index 9427): One-hot: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M04\n",
      "Sample 3 (index 199): One-hot: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M01\n",
      "Sample 4 (index 12447): One-hot: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M05\n",
      "Sample 5 (index 39489): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], Mechanism Label: M16\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "y_test shape: (100000, 20)\n",
      "Format: one-hot encoding\n",
      "\n",
      "Unique mechanism labels in y_test: ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07', 'M08', 'M09', 'M10', 'M11', 'M12', 'M13', 'M14', 'M15', 'M16', 'M17', 'M18', 'M19', 'M20']\n",
      "Sample 1 (index 75721): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], Mechanism Label: M16\n",
      "Sample 2 (index 80184): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], Mechanism Label: M17\n",
      "Sample 3 (index 19864): One-hot: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], Mechanism Label: M04\n",
      "Sample 4 (index 76699): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], Mechanism Label: M16\n",
      "Sample 5 (index 92991): One-hot: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], Mechanism Label: M19\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The label for each sample is the corresponding mechanism used to generate its kinetic data, encoded as a one-hot vector as follows:\n",
      "\n",
      "M 1: (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 2: (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 3: (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 4: (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 5: (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 6: (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 7: (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 8: (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M 9: (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M10: (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M11: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M12: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
      "M13: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
      "M14: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0)\n",
      "M15: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0)\n",
      "M16: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0)\n",
      "M17: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0)\n",
      "M18: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0)\n",
      "M19: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0)\n",
      "M20: (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "def check_one_hot(arr):\n",
    "    if arr.ndim != 2 or arr.shape[1] != 20:\n",
    "        return False\n",
    "    row_sums = np.sum(arr, axis=1)\n",
    "    return np.all((row_sums == 1) & (np.count_nonzero(arr, axis=1) == 1))\n",
    "\n",
    "def print_label_info(arr, name, n_show=5, seed=42):\n",
    "    print(f\"{name} shape: {arr.shape}\")\n",
    "    if check_one_hot(arr):\n",
    "        print(\"Format: one-hot encoding\\n\")\n",
    "        unique_indices = np.unique(np.argmax(arr, axis=1))\n",
    "        print(f\"Unique mechanism labels in {name}: {[f'M{idx+1:02d}' for idx in unique_indices]}\")\n",
    "        np.random.seed(seed)\n",
    "        indices = np.random.choice(arr.shape[0], n_show, replace=False)\n",
    "        for i, idx in enumerate(indices):\n",
    "            label = np.argmax(arr[idx])\n",
    "            one_hot_str = ', '.join(str(int(x)) for x in arr[idx])\n",
    "            print(f\"Sample {i+1} (index {idx}): One-hot: [{one_hot_str}], Mechanism Label: M{label+1:02d}\")\n",
    "    else:\n",
    "        print(\"Format: NOT one-hot encoding\")\n",
    "    print()\n",
    "    print('-'*80)\n",
    "\n",
    "print_label_info(y_train, \"y_train\")\n",
    "print_label_info(y_val, \"y_val\")\n",
    "print_label_info(y_test, \"y_test\")\n",
    "\n",
    "print(\"The label for each sample is the corresponding mechanism used to generate its kinetic data, encoded as a one-hot vector as follows:\\n\")\n",
    "for i in range(20):\n",
    "    vec = ['0']*20\n",
    "    vec[i] = '1'\n",
    "    print(f\"M{i+1:>2}: ({', '.join(vec)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c0a63-6709-4171-abc2-73eebf5dee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_classifier(input1_shape, input2_shape, output_shape, dropout_rate=0.3):\n",
    "    initial_concentrations = Input(shape=input1_shape)\n",
    "    kinetics = Input(shape=(None, input2_shape[-1]))\n",
    "\n",
    "    c = Dense(64, activation='relu')(initial_concentrations)\n",
    "    c = Dropout(dropout_rate)(c)\n",
    "\n",
    "    k = LSTM(64, return_sequences=True, dropout=dropout_rate)(kinetics)\n",
    "    k = LSTM(64, dropout=dropout_rate)(k)\n",
    "    k = Dropout(dropout_rate)(k)\n",
    "\n",
    "    combined = concatenate([c, k])\n",
    "    pred = Dense(64, activation='relu', kernel_initializer='he_uniform')(combined)\n",
    "    pred = Dropout(dropout_rate)(pred)\n",
    "    pred = Dense(output_shape[1], activation='softmax', name='Dense_5')(pred)\n",
    "\n",
    "    model = Model(inputs=[initial_concentrations, kinetics], outputs=pred)\n",
    "    return model\n",
    "\n",
    "class KineticsBatchGenerator(Sequence):\n",
    "    def __init__(self, X, y, tps, error_range, seed_value=1, batch_size=1024, shuffle=True):\n",
    "        self.x1, self.x2 = X\n",
    "        self.y = y\n",
    "        self.tps = tps\n",
    "        self.error_range = error_range\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.total_batches = self.__len__()\n",
    "        self.n_runs = 4\n",
    "        self.species = [1, 2]\n",
    "        self.error_species = len(self.species)\n",
    "        self.error_dict = {key: [] for key in error_range}\n",
    "        np.random.seed(seed_value)\n",
    "        self.randomstate = np.random.default_rng(seed_value)\n",
    "        self.on_epoch_end()\n",
    "        examples, timepoints, curves = self.x2.shape\n",
    "        columns = curves // self.n_runs\n",
    "        self.index_species = []\n",
    "        for i in range(self.n_runs):\n",
    "            t_species = [a + (i * columns) for a in self.species]\n",
    "            self.index_species = self.index_species + t_species\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        for error in self.error_range:\n",
    "            if error != 0:\n",
    "                preu = np.array([gauss(0, error / 100) for _ in range(self.batch_size * np.max(self.tps) * self.error_species * self.n_runs)])\n",
    "                self.error_dict[error] = np.reshape(preu, (self.batch_size, np.max(self.tps), self.error_species * self.n_runs))\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        x1 = self.x1[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x2 = self.introduce_error(self.trim_x2(self.x2[self.batch_size * index: self.batch_size * (index + 1)], self.tps, index))\n",
    "        y = self.y[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x = [x1, x2]\n",
    "        return x, y\n",
    "\n",
    "    def trim_x2(self, original_x2, tps, index):\n",
    "        original_tps = original_x2.shape[1]\n",
    "        n_tps = self.randomstate.choice(tps)\n",
    "        idx = np.sort(np.append(self.randomstate.choice(original_tps - 1, n_tps, replace=False) + 1, [0]))\n",
    "        return original_x2[:, idx].copy()\n",
    "\n",
    "    def introduce_error(self, x2):\n",
    "        examples, timepoints, curves = x2.shape\n",
    "        error = self.randomstate.choice(self.error_range)\n",
    "        if error != 0:\n",
    "            x2[:, 1:, self.index_species] = x2[:, 1:, self.index_species] + self.error_dict[error][:, 0:timepoints - 1]\n",
    "        return x2\n",
    "\n",
    "def get_top_mechanism_indices(predictions):\n",
    "    threshold = 0.99\n",
    "    index = np.argsort(predictions)\n",
    "    prob = 0\n",
    "    grouping = []\n",
    "    for j in index[::-1]:\n",
    "        prob += predictions[j]\n",
    "        grouping.append(j)\n",
    "        if prob >= threshold:\n",
    "            break\n",
    "    return grouping\n",
    "\n",
    "def mechanism_indices_to_names(indices):\n",
    "    mechanism_list = ['M' + str(i) for i in range(1, 21)]\n",
    "    grouping_names = [mechanism_list[i] for i in indices]\n",
    "    return grouping_names\n",
    "\n",
    "def plot_kinetic_profiles_and_mechanisms(x_list, mechanism_names, columns=3, s=30, A0=1, show=True, overlay=False, labels=None):\n",
    "    x1, x2 = x_list\n",
    "    rows = len(x1)\n",
    "    curves = x2.shape[2] // columns\n",
    "    if not overlay:\n",
    "        plt.figure(figsize=(4 * columns, 7 * rows))\n",
    "    i = 1\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            plt.subplot(2, columns, i)\n",
    "            if not overlay:\n",
    "                if column == 3:\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5))\n",
    "                else:\n",
    "                    percentage = ' (' + str(round(x1[row, column] / A0 * 100, 3)) + ' mol%)'\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5)) + percentage\n",
    "                plt.title(title)\n",
    "            if type(labels) == list:\n",
    "                label = labels\n",
    "            else:\n",
    "                label = None\n",
    "            for j in range(1, curves):\n",
    "                if type(labels) == list:\n",
    "                    label = labels[j - 1]\n",
    "                else:\n",
    "                    label = None\n",
    "                plt.scatter(x2[row, :, column * curves], x2[row, :, (j) + column * curves], s, label=label)\n",
    "            if not overlay:\n",
    "                plt.xlim(left=0, right=max(x2[row, :, column * curves]) * 1.1)\n",
    "                plt.ylim(bottom=0)\n",
    "            i += 1\n",
    "    plt.tight_layout()\n",
    "    mechs = []\n",
    "    for i, name in enumerate(mechanism_names):\n",
    "        mechs.append(img.imread('Images/' + name + '.jpg'))\n",
    "    length = len(mechs)\n",
    "    for i, mech in enumerate(mechs):\n",
    "        plt.subplot(2, length, length + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mech)\n",
    "\n",
    "MODEL_COLUMN_MAP = {\n",
    "    'M1_20_model_bayes': ['Time', 'S', 'P', 'catT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2aad58-bdc2-479b-b54e-91222e65f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mechanism_model(\n",
    "    tps = [3,4,5,6,7,8,9,10,15,20],\n",
    "    error_range = [0],\n",
    "    epochs = 3000,\n",
    "    start = 0,\n",
    "    batch_size_training = 4092\n",
    "):\n",
    "    x1_train, x2_train, y_train, x1_val, x2_val, y_val, x1_test, x2_test, y_test = load_datasets()\n",
    "\n",
    "    model = build_lstm_classifier(\n",
    "        input1_shape = x1_train.shape[1:],\n",
    "        input2_shape = x2_train.shape[1:],\n",
    "        output_shape = y_train.shape  \n",
    "    )\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"trained_model/best_model_weights\",\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        KineticsBatchGenerator([x1_train, x2_train], y_train, tps, error_range, batch_size=batch_size_training),\n",
    "        validation_data=KineticsBatchGenerator([x1_val, x2_val], y_val, tps, error_range, batch_size=25),\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        epochs=start+epochs,\n",
    "        initial_epoch=start\n",
    "    )\n",
    "\n",
    "    model.save('trained_model/M1_20_model_bayes')\n",
    "    print('Training completed. Optimal weights saved to: trained_model/best_model_weights')\n",
    "    print('Trained model saved to: trained_model/M1_20_model_bayes')\n",
    "    return model\n",
    "\n",
    "model = train_mechanism_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fe2c4-693e-48d1-b5ad-d9f9b94fb958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict(model, x_inputs, n_mc=100):\n",
    "    preds = [model(x_inputs, training=True).numpy() for _ in range(n_mc)]\n",
    "    all_probs = np.stack(preds, axis=0)\n",
    "    mean_probs = all_probs.mean(axis=0)\n",
    "    std_probs = all_probs.std(axis=0)\n",
    "    return mean_probs, std_probs, all_probs\n",
    "\n",
    "def credible_set(probs, threshold=0.95):\n",
    "    idx = np.argsort(probs)[::-1]\n",
    "    cumsum = np.cumsum(probs[idx])\n",
    "    k = np.searchsorted(cumsum, threshold) + 1\n",
    "    return idx[:k]\n",
    "\n",
    "def mechanism_indices_to_names(indices):\n",
    "    mechanism_list = ['M' + str(i) for i in range(1, 21)]\n",
    "    return [mechanism_list[i] for i in indices]\n",
    "\n",
    "model = load_model('trained_model/M1_20_model_bayes', compile=False)\n",
    "model.load_weights('trained_model/best_model_weights')\n",
    "\n",
    "mean_probs, std_probs, all_probs = mc_dropout_predict(model, [x1_test, x2_test], n_mc=100)\n",
    "entropies = entropy(mean_probs.T).T\n",
    "credible_sets = [credible_set(p, 0.95) for p in mean_probs]\n",
    "\n",
    "np.savez('bayesian_results_mc_dropout.npz',\n",
    "         mean_probs=mean_probs,\n",
    "         std_probs=std_probs,\n",
    "         entropies=entropies,\n",
    "         credible_sets=credible_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262284c2-9164-4b68-86fc-f0e4248e96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_classifier(input1_shape, input2_shape, output_shape, dropout_rate=0.3):\n",
    "    initial_concentrations = Input(shape=input1_shape)\n",
    "    kinetics = Input(shape=(None, input2_shape[-1]))\n",
    "\n",
    "    c = Dense(64, activation='relu')(initial_concentrations)\n",
    "    c = Dropout(dropout_rate)(c)\n",
    "\n",
    "    k = LSTM(64, return_sequences=True, dropout=dropout_rate)(kinetics)\n",
    "    k = LSTM(64, dropout=dropout_rate)(k)\n",
    "    k = Dropout(dropout_rate)(k)\n",
    "\n",
    "    #combined = concatenate([c, k])\n",
    "    \n",
    "    combined_raw = concatenate([c, k])\n",
    "    attention_weights = Dense(combined_raw.shape[-1], activation='softmax')(combined_raw)\n",
    "    combined = Multiply()([combined_raw, attention_weights])\n",
    "\n",
    "    pred = Dense(64, activation='relu', kernel_initializer='he_uniform')(combined)\n",
    "    pred = Dropout(dropout_rate)(pred)\n",
    "    pred = Dense(output_shape[1], activation='softmax', name='Dense_5')(pred)\n",
    "\n",
    "    model = Model(inputs=[initial_concentrations, kinetics], outputs=pred)\n",
    "    return model\n",
    "\n",
    "class KineticsBatchGenerator(Sequence):\n",
    "    def __init__(self, X, y, tps, error_range, seed_value=1, batch_size=1024, shuffle=True):\n",
    "        self.x1, self.x2 = X\n",
    "        self.y = y\n",
    "        self.tps = tps\n",
    "        self.error_range = error_range\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.total_batches = self.__len__()\n",
    "        self.n_runs = 4\n",
    "        self.species = [1, 2]\n",
    "        self.error_species = len(self.species)\n",
    "        self.error_dict = {key: [] for key in error_range}\n",
    "        np.random.seed(seed_value)\n",
    "        self.randomstate = np.random.default_rng(seed_value)\n",
    "        self.on_epoch_end()\n",
    "        examples, timepoints, curves = self.x2.shape\n",
    "        columns = curves // self.n_runs\n",
    "        self.index_species = []\n",
    "        for i in range(self.n_runs):\n",
    "            t_species = [a + (i * columns) for a in self.species]\n",
    "            self.index_species = self.index_species + t_species\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        for error in self.error_range:\n",
    "            if error != 0:\n",
    "                preu = np.array([gauss(0, error / 100) for _ in range(self.batch_size * np.max(self.tps) * self.error_species * self.n_runs)])\n",
    "                self.error_dict[error] = np.reshape(preu, (self.batch_size, np.max(self.tps), self.error_species * self.n_runs))\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        x1 = self.x1[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x2 = self.introduce_error(self.trim_x2(self.x2[self.batch_size * index: self.batch_size * (index + 1)], self.tps, index))\n",
    "        y = self.y[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x = [x1, x2]\n",
    "        return x, y\n",
    "\n",
    "    def trim_x2(self, original_x2, tps, index):\n",
    "        original_tps = original_x2.shape[1]\n",
    "        n_tps = self.randomstate.choice(tps)\n",
    "        idx = np.sort(np.append(self.randomstate.choice(original_tps - 1, n_tps, replace=False) + 1, [0]))\n",
    "        return original_x2[:, idx].copy()\n",
    "\n",
    "    def introduce_error(self, x2):\n",
    "        examples, timepoints, curves = x2.shape\n",
    "        error = self.randomstate.choice(self.error_range)\n",
    "        if error != 0:\n",
    "            x2[:, 1:, self.index_species] = x2[:, 1:, self.index_species] + self.error_dict[error][:, 0:timepoints - 1]\n",
    "        return x2\n",
    "\n",
    "def get_top_mechanism_indices(predictions):\n",
    "    threshold = 0.99\n",
    "    index = np.argsort(predictions)\n",
    "    prob = 0\n",
    "    grouping = []\n",
    "    for j in index[::-1]:\n",
    "        prob += predictions[j]\n",
    "        grouping.append(j)\n",
    "        if prob >= threshold:\n",
    "            break\n",
    "    return grouping\n",
    "\n",
    "def mechanism_indices_to_names(indices):\n",
    "    mechanism_list = ['M' + str(i) for i in range(1, 21)]\n",
    "    grouping_names = [mechanism_list[i] for i in indices]\n",
    "    return grouping_names\n",
    "\n",
    "def plot_kinetic_profiles_and_mechanisms(x_list, mechanism_names, columns=3, s=30, A0=1, show=True, overlay=False, labels=None):\n",
    "    x1, x2 = x_list\n",
    "    rows = len(x1)\n",
    "    curves = x2.shape[2] // columns\n",
    "    if not overlay:\n",
    "        plt.figure(figsize=(4 * columns, 7 * rows))\n",
    "    i = 1\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            plt.subplot(2, columns, i)\n",
    "            if not overlay:\n",
    "                if column == 3:\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5))\n",
    "                else:\n",
    "                    percentage = ' (' + str(round(x1[row, column] / A0 * 100, 3)) + ' mol%)'\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5)) + percentage\n",
    "                plt.title(title)\n",
    "            if type(labels) == list:\n",
    "                label = labels\n",
    "            else:\n",
    "                label = None\n",
    "            for j in range(1, curves):\n",
    "                if type(labels) == list:\n",
    "                    label = labels[j - 1]\n",
    "                else:\n",
    "                    label = None\n",
    "                plt.scatter(x2[row, :, column * curves], x2[row, :, (j) + column * curves], s, label=label)\n",
    "            if not overlay:\n",
    "                plt.xlim(left=0, right=max(x2[row, :, column * curves]) * 1.1)\n",
    "                plt.ylim(bottom=0)\n",
    "            i += 1\n",
    "    plt.tight_layout()\n",
    "    mechs = []\n",
    "    for i, name in enumerate(mechanism_names):\n",
    "        mechs.append(img.imread('Images/' + name + '.jpg'))\n",
    "    length = len(mechs)\n",
    "    for i, mech in enumerate(mechs):\n",
    "        plt.subplot(2, length, length + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mech)\n",
    "\n",
    "MODEL_COLUMN_MAP = {\n",
    "    'M1_20_model_bayes': ['Time', 'S', 'P', 'catT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01ea05-c44a-4f29-8fb0-4f54ccb72a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mechanism_model(\n",
    "    tps = [3,4,5,6,7,8,9,10,15,20],\n",
    "    error_range = [0],\n",
    "    epochs = 3000,\n",
    "    start = 0,\n",
    "    batch_size_training = 4092\n",
    "):\n",
    "    x1_train, x2_train, y_train, x1_val, x2_val, y_val, x1_test, x2_test, y_test = load_datasets()\n",
    "\n",
    "    model = build_lstm_classifier(\n",
    "        input1_shape = x1_train.shape[1:],\n",
    "        input2_shape = x2_train.shape[1:],\n",
    "        output_shape = y_train.shape  \n",
    "    )\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"trained_model/best_model_weights\",\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        KineticsBatchGenerator([x1_train, x2_train], y_train, tps, error_range, batch_size=batch_size_training),\n",
    "        validation_data=KineticsBatchGenerator([x1_val, x2_val], y_val, tps, error_range, batch_size=25),\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        epochs=start+epochs,\n",
    "        initial_epoch=start\n",
    "    )\n",
    "\n",
    "    model.save('trained_model/M1_20_model_bayes')\n",
    "    print('Training completed. Optimal weights saved to: trained_model/best_model_weights')\n",
    "    print('Trained model saved to: trained_model/M1_20_model_bayes')\n",
    "    return model\n",
    "\n",
    "model = train_mechanism_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60caa5b3-d950-4503-bb83-0f7557202672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_classifier(input1_shape, input2_shape, output_shape, dropout_rate=0.3):\n",
    "    initial_concentrations = Input(shape=input1_shape)\n",
    "    kinetics = Input(shape=(None, input2_shape[-1]))\n",
    "\n",
    "    c = Dense(64, activation='relu')(initial_concentrations)\n",
    "    c = Dropout(dropout_rate)(c)\n",
    "\n",
    "    k = LSTM(64, return_sequences=True, dropout=dropout_rate)(kinetics)\n",
    "    k = LSTM(64, dropout=dropout_rate)(k)\n",
    "    k = Dropout(dropout_rate)(k)\n",
    "\n",
    "    #combined = concatenate([c, k])\n",
    "    \n",
    "    #ccombined_raw = concatenate([c, k])\n",
    "    #cattention_weights = Dense(combined_raw.shape[-1], activation='softmax')(combined_raw)\n",
    "    #ccombined = Multiply()([combined_raw, attention_weights])\n",
    "\n",
    "    c_proj = Dense(64)(c)\n",
    "    k_proj = Dense(64)(k)\n",
    "    alpha = Dense(64, activation='sigmoid')(c_proj) \n",
    "    beta = Dense(64, activation='sigmoid')(k_proj)   \n",
    "    c_weighted = Multiply()([alpha, c_proj])\n",
    "    k_weighted = Multiply()([beta, k_proj])\n",
    "    combined = Add()([c_weighted, k_weighted])\n",
    "\n",
    "    pred = Dense(64, activation='relu', kernel_initializer='he_uniform')(combined)\n",
    "    pred = Dropout(dropout_rate)(pred)\n",
    "    pred = Dense(output_shape[1], activation='softmax', name='Dense_5')(pred)\n",
    "\n",
    "    model = Model(inputs=[initial_concentrations, kinetics], outputs=pred)\n",
    "    return model\n",
    "\n",
    "class KineticsBatchGenerator(Sequence):\n",
    "    def __init__(self, X, y, tps, error_range, seed_value=1, batch_size=1024, shuffle=True):\n",
    "        self.x1, self.x2 = X\n",
    "        self.y = y\n",
    "        self.tps = tps\n",
    "        self.error_range = error_range\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.total_batches = self.__len__()\n",
    "        self.n_runs = 4\n",
    "        self.species = [1, 2]\n",
    "        self.error_species = len(self.species)\n",
    "        self.error_dict = {key: [] for key in error_range}\n",
    "        np.random.seed(seed_value)\n",
    "        self.randomstate = np.random.default_rng(seed_value)\n",
    "        self.on_epoch_end()\n",
    "        examples, timepoints, curves = self.x2.shape\n",
    "        columns = curves // self.n_runs\n",
    "        self.index_species = []\n",
    "        for i in range(self.n_runs):\n",
    "            t_species = [a + (i * columns) for a in self.species]\n",
    "            self.index_species = self.index_species + t_species\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        for error in self.error_range:\n",
    "            if error != 0:\n",
    "                preu = np.array([gauss(0, error / 100) for _ in range(self.batch_size * np.max(self.tps) * self.error_species * self.n_runs)])\n",
    "                self.error_dict[error] = np.reshape(preu, (self.batch_size, np.max(self.tps), self.error_species * self.n_runs))\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        x1 = self.x1[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x2 = self.introduce_error(self.trim_x2(self.x2[self.batch_size * index: self.batch_size * (index + 1)], self.tps, index))\n",
    "        y = self.y[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x = [x1, x2]\n",
    "        return x, y\n",
    "\n",
    "    def trim_x2(self, original_x2, tps, index):\n",
    "        original_tps = original_x2.shape[1]\n",
    "        n_tps = self.randomstate.choice(tps)\n",
    "        idx = np.sort(np.append(self.randomstate.choice(original_tps - 1, n_tps, replace=False) + 1, [0]))\n",
    "        return original_x2[:, idx].copy()\n",
    "\n",
    "    def introduce_error(self, x2):\n",
    "        examples, timepoints, curves = x2.shape\n",
    "        error = self.randomstate.choice(self.error_range)\n",
    "        if error != 0:\n",
    "            x2[:, 1:, self.index_species] = x2[:, 1:, self.index_species] + self.error_dict[error][:, 0:timepoints - 1]\n",
    "        return x2\n",
    "\n",
    "def get_top_mechanism_indices(predictions):\n",
    "    threshold = 0.99\n",
    "    index = np.argsort(predictions)\n",
    "    prob = 0\n",
    "    grouping = []\n",
    "    for j in index[::-1]:\n",
    "        prob += predictions[j]\n",
    "        grouping.append(j)\n",
    "        if prob >= threshold:\n",
    "            break\n",
    "    return grouping\n",
    "\n",
    "def mechanism_indices_to_names(indices):\n",
    "    mechanism_list = ['M' + str(i) for i in range(1, 21)]\n",
    "    grouping_names = [mechanism_list[i] for i in indices]\n",
    "    return grouping_names\n",
    "\n",
    "def plot_kinetic_profiles_and_mechanisms(x_list, mechanism_names, columns=3, s=30, A0=1, show=True, overlay=False, labels=None):\n",
    "    x1, x2 = x_list\n",
    "    rows = len(x1)\n",
    "    curves = x2.shape[2] // columns\n",
    "    if not overlay:\n",
    "        plt.figure(figsize=(4 * columns, 7 * rows))\n",
    "    i = 1\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            plt.subplot(2, columns, i)\n",
    "            if not overlay:\n",
    "                if column == 3:\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5))\n",
    "                else:\n",
    "                    percentage = ' (' + str(round(x1[row, column] / A0 * 100, 3)) + ' mol%)'\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5)) + percentage\n",
    "                plt.title(title)\n",
    "            if type(labels) == list:\n",
    "                label = labels\n",
    "            else:\n",
    "                label = None\n",
    "            for j in range(1, curves):\n",
    "                if type(labels) == list:\n",
    "                    label = labels[j - 1]\n",
    "                else:\n",
    "                    label = None\n",
    "                plt.scatter(x2[row, :, column * curves], x2[row, :, (j) + column * curves], s, label=label)\n",
    "            if not overlay:\n",
    "                plt.xlim(left=0, right=max(x2[row, :, column * curves]) * 1.1)\n",
    "                plt.ylim(bottom=0)\n",
    "            i += 1\n",
    "    plt.tight_layout()\n",
    "    mechs = []\n",
    "    for i, name in enumerate(mechanism_names):\n",
    "        mechs.append(img.imread('Images/' + name + '.jpg'))\n",
    "    length = len(mechs)\n",
    "    for i, mech in enumerate(mechs):\n",
    "        plt.subplot(2, length, length + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mech)\n",
    "\n",
    "MODEL_COLUMN_MAP = {\n",
    "    'M1_20_model_bayes': ['Time', 'S', 'P', 'catT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69945005-1495-4998-827d-d6c49656acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "  72/1209 [>.............................] - ETA: 1:47 - loss: 3.0047 - categorical_accuracy: 0.0360"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrained model saved to: trained_model/M1_20_model_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mechanism_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m, in \u001b[0;36mtrain_mechanism_model\u001b[0;34m(tps, error_range, epochs, start, batch_size_training)\u001b[0m\n\u001b[1;32m     18\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     19\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/best_model_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mKineticsBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_training\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKineticsBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model/M1_20_model_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining completed. Optimal weights saved to: trained_model/best_model_weights\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_mechanism_model(\n",
    "    tps = [3,4,5,6,7,8,9,10,15,20],\n",
    "    error_range = [0],\n",
    "    epochs = 3000,\n",
    "    start = 0,\n",
    "    batch_size_training = 4092\n",
    "):\n",
    "    x1_train, x2_train, y_train, x1_val, x2_val, y_val, x1_test, x2_test, y_test = load_datasets()\n",
    "\n",
    "    model = build_lstm_classifier(\n",
    "        input1_shape = x1_train.shape[1:],\n",
    "        input2_shape = x2_train.shape[1:],\n",
    "        output_shape = y_train.shape  \n",
    "    )\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"trained_model/best_model_weights\",\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        KineticsBatchGenerator([x1_train, x2_train], y_train, tps, error_range, batch_size=batch_size_training),\n",
    "        validation_data=KineticsBatchGenerator([x1_val, x2_val], y_val, tps, error_range, batch_size=25),\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        epochs=start+epochs,\n",
    "        initial_epoch=start\n",
    "    )\n",
    "\n",
    "    model.save('trained_model/M1_20_model_bayes')\n",
    "    print('Training completed. Optimal weights saved to: trained_model/best_model_weights')\n",
    "    print('Trained model saved to: trained_model/M1_20_model_bayes')\n",
    "    return model\n",
    "\n",
    "model = train_mechanism_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e862847-d37c-44d5-bf8f-40dcfea6f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_classifier(input1_shape, input2_shape, output_shape, dropout_rate=0.3):\n",
    "    initial_concentrations = Input(shape=input1_shape)\n",
    "    kinetics = Input(shape=(None, input2_shape[-1]))\n",
    "\n",
    "    c = Dense(64, activation='relu')(initial_concentrations)\n",
    "    c = Dropout(dropout_rate)(c)\n",
    "\n",
    "    k = LSTM(64, return_sequences=True, dropout=dropout_rate)(kinetics)\n",
    "    k = LSTM(64, dropout=dropout_rate)(k)\n",
    "    k = Dropout(dropout_rate)(k)\n",
    "\n",
    "    #combined = concatenate([c, k])\n",
    "    \n",
    "    #ccombined_raw = concatenate([c, k])\n",
    "    #cattention_weights = Dense(combined_raw.shape[-1], activation='softmax')(combined_raw)\n",
    "    #ccombined = Multiply()([combined_raw, attention_weights])\n",
    "\n",
    "    #c_proj = Dense(64)(c)\n",
    "    # k_proj = Dense(64)(k)\n",
    "    # alpha = Dense(64, activation='sigmoid')(c_proj) \n",
    "    # beta = Dense(64, activation='sigmoid')(k_proj)   \n",
    "    # c_weighted = Multiply()([alpha, c_proj])\n",
    "    # k_weighted = Multiply()([beta, k_proj])\n",
    "    # combined = Add()([c_weighted, k_weighted])\n",
    "\n",
    "    dim = 64\n",
    "    c_proj = Dense(dim)(c)\n",
    "    k_proj = Dense(dim)(k)\n",
    "    combined = tf.keras.layers.Multiply()([c_proj, k_proj])\n",
    "    combined = Dense(64, activation='relu')(combined)  \n",
    " \n",
    "    pred = Dense(64, activation='relu', kernel_initializer='he_uniform')(combined)\n",
    "    pred = Dropout(dropout_rate)(pred)\n",
    "    pred = Dense(output_shape[1], activation='softmax', name='Dense_5')(pred)\n",
    "\n",
    "    model = Model(inputs=[initial_concentrations, kinetics], outputs=pred)\n",
    "    return model\n",
    "\n",
    "class KineticsBatchGenerator(Sequence):\n",
    "    def __init__(self, X, y, tps, error_range, seed_value=1, batch_size=1024, shuffle=True):\n",
    "        self.x1, self.x2 = X\n",
    "        self.y = y\n",
    "        self.tps = tps\n",
    "        self.error_range = error_range\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.total_batches = self.__len__()\n",
    "        self.n_runs = 4\n",
    "        self.species = [1, 2]\n",
    "        self.error_species = len(self.species)\n",
    "        self.error_dict = {key: [] for key in error_range}\n",
    "        np.random.seed(seed_value)\n",
    "        self.randomstate = np.random.default_rng(seed_value)\n",
    "        self.on_epoch_end()\n",
    "        examples, timepoints, curves = self.x2.shape\n",
    "        columns = curves // self.n_runs\n",
    "        self.index_species = []\n",
    "        for i in range(self.n_runs):\n",
    "            t_species = [a + (i * columns) for a in self.species]\n",
    "            self.index_species = self.index_species + t_species\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.y))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        for error in self.error_range:\n",
    "            if error != 0:\n",
    "                preu = np.array([gauss(0, error / 100) for _ in range(self.batch_size * np.max(self.tps) * self.error_species * self.n_runs)])\n",
    "                self.error_dict[error] = np.reshape(preu, (self.batch_size, np.max(self.tps), self.error_species * self.n_runs))\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        x1 = self.x1[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x2 = self.introduce_error(self.trim_x2(self.x2[self.batch_size * index: self.batch_size * (index + 1)], self.tps, index))\n",
    "        y = self.y[self.batch_size * index: self.batch_size * (index + 1)]\n",
    "        x = [x1, x2]\n",
    "        return x, y\n",
    "\n",
    "    def trim_x2(self, original_x2, tps, index):\n",
    "        original_tps = original_x2.shape[1]\n",
    "        n_tps = self.randomstate.choice(tps)\n",
    "        idx = np.sort(np.append(self.randomstate.choice(original_tps - 1, n_tps, replace=False) + 1, [0]))\n",
    "        return original_x2[:, idx].copy()\n",
    "\n",
    "    def introduce_error(self, x2):\n",
    "        examples, timepoints, curves = x2.shape\n",
    "        error = self.randomstate.choice(self.error_range)\n",
    "        if error != 0:\n",
    "            x2[:, 1:, self.index_species] = x2[:, 1:, self.index_species] + self.error_dict[error][:, 0:timepoints - 1]\n",
    "        return x2\n",
    "\n",
    "def get_top_mechanism_indices(predictions):\n",
    "    threshold = 0.99\n",
    "    index = np.argsort(predictions)\n",
    "    prob = 0\n",
    "    grouping = []\n",
    "    for j in index[::-1]:\n",
    "        prob += predictions[j]\n",
    "        grouping.append(j)\n",
    "        if prob >= threshold:\n",
    "            break\n",
    "    return grouping\n",
    "\n",
    "def mechanism_indices_to_names(indices):\n",
    "    mechanism_list = ['M' + str(i) for i in range(1, 21)]\n",
    "    grouping_names = [mechanism_list[i] for i in indices]\n",
    "    return grouping_names\n",
    "\n",
    "def plot_kinetic_profiles_and_mechanisms(x_list, mechanism_names, columns=3, s=30, A0=1, show=True, overlay=False, labels=None):\n",
    "    x1, x2 = x_list\n",
    "    rows = len(x1)\n",
    "    curves = x2.shape[2] // columns\n",
    "    if not overlay:\n",
    "        plt.figure(figsize=(4 * columns, 7 * rows))\n",
    "    i = 1\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            plt.subplot(2, columns, i)\n",
    "            if not overlay:\n",
    "                if column == 3:\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5))\n",
    "                else:\n",
    "                    percentage = ' (' + str(round(x1[row, column] / A0 * 100, 3)) + ' mol%)'\n",
    "                    title = r'[Cat]$_{0}$ = ' + str(round(x1[row, column], 5)) + percentage\n",
    "                plt.title(title)\n",
    "            if type(labels) == list:\n",
    "                label = labels\n",
    "            else:\n",
    "                label = None\n",
    "            for j in range(1, curves):\n",
    "                if type(labels) == list:\n",
    "                    label = labels[j - 1]\n",
    "                else:\n",
    "                    label = None\n",
    "                plt.scatter(x2[row, :, column * curves], x2[row, :, (j) + column * curves], s, label=label)\n",
    "            if not overlay:\n",
    "                plt.xlim(left=0, right=max(x2[row, :, column * curves]) * 1.1)\n",
    "                plt.ylim(bottom=0)\n",
    "            i += 1\n",
    "    plt.tight_layout()\n",
    "    mechs = []\n",
    "    for i, name in enumerate(mechanism_names):\n",
    "        mechs.append(img.imread('Images/' + name + '.jpg'))\n",
    "    length = len(mechs)\n",
    "    for i, mech in enumerate(mechs):\n",
    "        plt.subplot(2, length, length + i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(mech)\n",
    "\n",
    "MODEL_COLUMN_MAP = {\n",
    "    'M1_20_model_bayes': ['Time', 'S', 'P', 'catT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd12818-7ed8-4035-8438-aa6f3a9023be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      " 679/1209 [===============>..............] - ETA: 1:04 - loss: 2.9061 - categorical_accuracy: 0.0765"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrained model saved to: trained_model/M1_20_model_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mechanism_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m, in \u001b[0;36mtrain_mechanism_model\u001b[0;34m(tps, error_range, epochs, start, batch_size_training)\u001b[0m\n\u001b[1;32m     18\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     19\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model/best_model_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mKineticsBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_training\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKineticsBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_model/M1_20_model_bayes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining completed. Optimal weights saved to: trained_model/best_model_weights\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sbi-mac-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_mechanism_model(\n",
    "    tps = [3,4,5,6,7,8,9,10,15,20],\n",
    "    error_range = [0],\n",
    "    epochs = 3000,\n",
    "    start = 0,\n",
    "    batch_size_training = 4092\n",
    "):\n",
    "    x1_train, x2_train, y_train, x1_val, x2_val, y_val, x1_test, x2_test, y_test = load_datasets()\n",
    "\n",
    "    model = build_lstm_classifier(\n",
    "        input1_shape = x1_train.shape[1:],\n",
    "        input2_shape = x2_train.shape[1:],\n",
    "        output_shape = y_train.shape  \n",
    "    )\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"trained_model/best_model_weights\",\n",
    "        monitor='val_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        KineticsBatchGenerator([x1_train, x2_train], y_train, tps, error_range, batch_size=batch_size_training),\n",
    "        validation_data=KineticsBatchGenerator([x1_val, x2_val], y_val, tps, error_range, batch_size=25),\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        epochs=start+epochs,\n",
    "        initial_epoch=start\n",
    "    )\n",
    "\n",
    "    model.save('trained_model/M1_20_model_bayes')\n",
    "    print('Training completed. Optimal weights saved to: trained_model/best_model_weights')\n",
    "    print('Trained model saved to: trained_model/M1_20_model_bayes')\n",
    "    return model\n",
    "\n",
    "model = train_mechanism_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0246a93-ab73-43e7-9356-8c15aa6d608a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi-mac-env",
   "language": "python",
   "name": "sbi-mac-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
